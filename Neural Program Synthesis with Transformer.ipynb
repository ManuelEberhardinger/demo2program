{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import karel_env.dataset_karel as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:168: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  num_train = int(f['data_info']['num_train'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:169: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  num_test = int(f['data_info']['num_test'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:170: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  num_val = int(f['data_info']['num_val'].value)\n",
      "\u001b[37m\u001b[1m[2021-12-26 17:51:44,345] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:29: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.dsl_type = self.data['data_info']['dsl_type'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:30: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.num_demo = int(self.data['data_info']['num_demo_per_program'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.max_demo_len = int(self.data['data_info']['max_demo_length'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:33: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.max_program_len = int(self.data['data_info']['max_program_length'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:34: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.num_program_tokens = int(self.data['data_info']['num_program_tokens'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:35: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.num_action_tokens = int(self.data['data_info']['num_action_tokens'].value)\n",
      "\u001b[37m\u001b[1m[2021-12-26 17:51:44,353] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 17:51:44,354] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 17:51:44,357] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 17:51:44,358] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 17:51:44,361] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:47: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  program_tokens = self.data[id]['program'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:53: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  demo_data = self.data[id]['s_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:54: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_demo_data = self.data[id]['test_s_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:60: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  per_data = self.data[id]['per'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:61: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_per_data = self.data[id]['test_per'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:70: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  action_history_tokens = self.data[id]['a_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:87: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_action_history_tokens = self.data[id]['test_a_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:107: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  demo_length = self.data[id]['s_h_len'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:108: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_demo_length = self.data[id]['test_s_h_len'].value\n"
     ]
    }
   ],
   "source": [
    "dataset_train, _, _ = dataset.create_default_splits('datasets/karel_dataset/', num_k=10)\n",
    "data_id = dataset_train.ids\n",
    "obs = dataset_train.get_data(data_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[2][:, :, :,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karel_env import karel_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "karel_util.state2symbol(dataset_train.get_data(data_id[1000])[3][4, 8, :,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karel_util.state2image(dataset_train.get_data(data_id[1000])[3][3, 5, :,:,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29, 29, 29, 30, 30, 29, 30, 25, 26, 13, 14,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [29, 29, 29, 30, 30, 30, 30, 29, 30, 13, 14,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [29, 29, 29, 30, 30, 29, 30,  9, 10,  0,  0,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [21, 21, 29, 30, 30, 29, 30, 29, 30, 29, 30, 21, 22, 13, 14, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [29, 29, 29, 30, 30, 29, 30, 13, 14,  0,  0,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [29, 29, 29, 30, 30, 29, 30, 13, 14,  0,  0,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [29, 29, 29, 30, 30, 29, 30, 29, 30, 13, 14,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [30, 30, 30, 30, 30, 29, 30, 13, 14,  0,  0,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [21, 21, 29, 30, 30, 30, 30, 29, 30, 13, 14,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33],\n",
       "       [25, 21, 29, 30, 30, 25, 26, 29, 30, 13, 14,  0,  0,  0,  0, 32,\n",
       "        33, 33, 33, 33]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pad_per_data = dataset_train.get_data(data_id[1000])[11]\n",
    "def convert_to_dec(row):\n",
    "    if 2 in row:\n",
    "        return 32\n",
    "    elif 3 in row:\n",
    "        return 33\n",
    "    else:\n",
    "        return int(''.join(row.astype(int).astype(str)), 2)\n",
    "\n",
    "np.apply_along_axis(convert_to_dec, 2, pad_per_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(20):\n",
    "    plt.imshow(karel_util.state2image(dataset_train.get_data(data_id[1000])[3][2, i, :,:,:]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy\n",
    "from karel_env.dsl import get_KarelDSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import karel_env.dataset_karel as dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class KarelVideoDataset(Dataset):\n",
    "    def __init__(self, dataset_path='datasets/karel_dataset/', num_k=10, \n",
    "                 train=False, test=False, val=False):\n",
    "        check_arr = [train, test, val]\n",
    "        if check_arr.count(True) == 0:\n",
    "            raise RuntimeError('No Dataset type specified')\n",
    "        \n",
    "        if check_arr.count(True) > 1:\n",
    "            raise RuntimeError('Multiple Dataset types specified')\n",
    "        \n",
    "        dataset_train, dataset_test, dataset_val \\\n",
    "            = dataset.create_default_splits(dataset_path, num_k=num_k)\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.val = val\n",
    "        \n",
    "        if self.train:\n",
    "            self.data_ids = dataset_train.ids#[:128]\n",
    "            self.dataset = dataset_train\n",
    "        elif self.test:\n",
    "            self.data_ids = dataset_test.ids#[:64]\n",
    "            self.dataset = dataset_test\n",
    "        else:\n",
    "            self.data_ids = dataset_val.ids\n",
    "            self.dataset = dataset_val\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_id = self.data_ids[idx]\n",
    "        data = self.dataset.get_data(data_id)\n",
    "        observation = data[2]\n",
    "        padded_program_tokens = data[1]\n",
    "        observation = torch.as_tensor(observation, dtype=torch.float32)\n",
    "        demo_length = torch.as_tensor(data[9], dtype=torch.float32)\n",
    "        padded_program_tokens = torch.as_tensor(padded_program_tokens, dtype=torch.long)\n",
    "        padded_action_history_tokens = torch.as_tensor(data[5], dtype=torch.long)\n",
    "        pad_per_data = torch.as_tensor(data[11], dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        \n",
    "        demo_length = torch.as_tensor(data[9], dtype=torch.long)\n",
    "        \"\"\" \n",
    "        get_data(id) returns:\n",
    "            0: program, \n",
    "            1: padded_program_tokens, \n",
    "            2: demo[:self.num_k], \n",
    "            3: test_demo, \n",
    "            4: action_history[:self.num_k], \n",
    "            5: padded_action_history_tokens[:self.num_k], \n",
    "            6: test_action_history, \n",
    "            7: padded_test_action_history_tokens, \n",
    "            8: program_length\n",
    "            9: demo_length[:self.num_k]\n",
    "            10: test_demo_length, \n",
    "            11: pad_per_data[:self.num_k], \n",
    "            12: pad_test_per_data\n",
    "            13: program tokens\n",
    "        \"\"\"\n",
    "        return observation, padded_program_tokens, padded_action_history_tokens, pad_per_data, demo_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KarelVideoDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # OPTIONAL, called for every GPU/machine (assigning state is OK)\n",
    "    def setup(self, stage = None):\n",
    "        # transforms\n",
    "        # split dataset\n",
    "        if stage in (None, \"fit\"):\n",
    "            # in the paper they use the test for training and not the val\n",
    "            # acutally the terms are somehow mixed \n",
    "            self.karel_train = KarelVideoDataset(train=True)\n",
    "            self.karel_val =  KarelVideoDataset(test=True)\n",
    "        if stage == \"test\":\n",
    "            self.karel_test = KarelVideoDataset(val=True)\n",
    "        if stage == \"predict\":\n",
    "            self.karel_predict = KarelVideoDataset(val=True)\n",
    "\n",
    "    # return the dataloader for each split\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.karel_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.karel_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.karel_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.karel_predict, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 50\n",
    "PAD_IDX_ACTION = 6\n",
    "PAD_IDX_PERCEPTION = 33\n",
    "class ProgramSynthesisTransformer(pl.LightningModule):\n",
    "    def __init__(self, depth=16, w=8, h=8, k=10, max_demo_len=20, max_program_len=43):\n",
    "        super().__init__()\n",
    "        self.dataset_type = 'karel'\n",
    "        self.dim_model = 256\n",
    "        self.depth = depth\n",
    "        self.k = k\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.max_demo_len = max_demo_len\n",
    "        self.max_program_len = max_program_len\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_program_acc = Accuracy()\n",
    "        self.val_program_acc = Accuracy()\n",
    "              \n",
    "        \"\"\"\n",
    "        The CNN for encoding of the single frames of the video. Adapted from the Original Tensorflow implementation\n",
    "        of the paper: Neural Program Synthesis from diverse Demonstration Videos.\n",
    "        \"\"\"\n",
    "        self.cnn_encoder = nn.Sequential(\n",
    "            nn.Conv2d(depth, 16, kernel_size=3, stride=2, padding=5),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.GroupNorm(1, 16),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=5),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            nn.GroupNorm(1, 32),\n",
    "            nn.Conv2d(32, 48, kernel_size=3, stride=2, padding=5),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.BatchNorm2d(48),\n",
    "            nn.GroupNorm(1, 48),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(48*self.h*self.w, self.dim_model)\n",
    "        )\n",
    "        self.vocab_size = 50 + 1\n",
    "        self.action_n = 5 + 1 + 1 # for pad token and EOS\n",
    "        self.perception_n = 5\n",
    "        self.perception_out_n = 34 # 0, 1 plus pad token and EOS\n",
    "        self.program_embedding = nn.Embedding(self.vocab_size, self.dim_model)\n",
    "        self.action_embedding = nn.Embedding(self.action_n, self.dim_model)\n",
    "        self.perception_embedding = nn.Embedding(self.perception_out_n, self.dim_model)\n",
    "        \n",
    "        \"\"\"\n",
    "        Transformer Encoder for the multiple demonstrations received from the CNNs with learned positional embeddings \n",
    "        similar to the Vision Transformer.\n",
    "        \"\"\"\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.dim_model, nhead=8, \n",
    "                                                   batch_first=True, dropout=0.3, activation='gelu',\n",
    "                                                   dim_feedforward=256)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
    "        self.transformer_encoder_out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.dim_model*self.max_demo_len, self.dim_model),\n",
    "        )\n",
    "        \n",
    "        # position embedding is learned, similar to ViT\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.max_demo_len + 1, self.dim_model))\n",
    "        \n",
    "        \"\"\"\n",
    "        Program Transformer with an Encoder-Decoder Architecture for creating the program from the output of \n",
    "        the transformer_encoder. Modelling the problem in an autoregressive way, predicting each token\n",
    "        after each other.\n",
    "        \"\"\"\n",
    "        self.transformer = nn.Transformer(nhead=8, num_encoder_layers=2,\n",
    "                                          num_decoder_layers=2, batch_first=True,\n",
    "                                          d_model=self.dim_model, dropout=0.3,\n",
    "                                          activation=\"gelu\", dim_feedforward=256)\n",
    "        self.out = nn.Linear(self.dim_model, self.vocab_size)\n",
    "        \n",
    "        # pos encoder for the program tokens, similar to original paper as we have tokens\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=self.dim_model, dropout_p=0.2, max_len=5000\n",
    "        )\n",
    "         \n",
    "        \"\"\"\n",
    "        Action Transformer\n",
    "        \"\"\"\n",
    "        self.action_transformer = nn.Transformer(nhead=4, num_encoder_layers=2,\n",
    "                                          num_decoder_layers=2, batch_first=True,\n",
    "                                          d_model=self.dim_model, dropout=0.3,\n",
    "                                          activation=\"gelu\", dim_feedforward=128)\n",
    "        self.action_out = nn.Linear(self.dim_model, self.action_n)\n",
    "        \n",
    "        \"\"\"\n",
    "        Perception Transformer\n",
    "        \"\"\"\n",
    "        self.perception_transformer = nn.Transformer(nhead=4, num_encoder_layers=2,\n",
    "                                          num_decoder_layers=2, batch_first=True,\n",
    "                                          d_model=self.dim_model, dropout=0.3,\n",
    "                                          activation=\"gelu\", dim_feedforward=128)\n",
    "        self.perception_out = nn.Linear(self.dim_model, self.perception_out_n)\n",
    "        \n",
    "        \"\"\"\n",
    "        Use Xavier Initialization for the weights.\n",
    "        \"\"\"\n",
    "        for p in self.transformer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                \n",
    "        for p in self.action_transformer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                \n",
    "        for p in self.perception_transformer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                        \n",
    "        for p in self.transformer_encoder.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        \n",
    "    # from: https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    def get_tgt_mask(self, tgt, pad_idx=None) -> torch.tensor:\n",
    "        size = tgt.size(1)\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        if pad_idx == None:\n",
    "            pad_idx = PAD_IDX\n",
    "        tgt_padding_mask = (tgt == pad_idx)\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask.to(self.device), tgt_padding_mask\n",
    "    \n",
    "    def get_src_padding_mask(self, demo_length):\n",
    "        mask = torch.ones((demo_length.size(0), demo_length.size(1), self.max_demo_len))\n",
    "        \n",
    "        for i in range(demo_length.size(0)):\n",
    "            for j in range(demo_length.size(1)):\n",
    "                mask[i, j, :demo_length[i][j]] = 0\n",
    "        mask = mask.bool()\n",
    "        return mask.to(self.device)\n",
    "        \n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "    \n",
    "    def stack_demos(self, x, batch_size, demo_length, src_pad_mask):\n",
    "        # (32, 10, 20, 8, 8, 16)\n",
    "        # (batch_size, demos, demo_len, w, h, depth)\n",
    "        demo_tensors = None\n",
    "        demo_list = []\n",
    "        for i in range(self.k):\n",
    "            s_h = x[:, i, :, :, :, :]\n",
    "            s_h = s_h.reshape([-1, self.h, self.w, self.depth]).permute(0, 3, 1, 2)\n",
    "            s_h = self.cnn_encoder(s_h)\n",
    "            s_h = s_h.reshape(batch_size, self.max_demo_len, -1)\n",
    "            s_h += self.pos_embedding[:, :self.max_demo_len]\n",
    "            # we add it for the perception and action transformer\n",
    "            demo_list.append(s_h)\n",
    "            s_t = self.transformer_encoder(s_h, src_key_padding_mask=src_pad_mask[:, i, :])\n",
    "            s_t = self.transformer_encoder_out(s_t)\n",
    "            if demo_tensors is None:\n",
    "                demo_tensors = s_t.unsqueeze(0)\n",
    "            else:\n",
    "                demo_tensors = torch.cat([demo_tensors, s_t.unsqueeze(0)])\n",
    "        \n",
    "        demo_tensors = demo_tensors.permute(1, 0, 2)\n",
    "        return demo_tensors, torch.stack(demo_list).to(self.device)\n",
    "    \n",
    "    def run_program_transformer(self, y, demo_tensors):\n",
    "        emb_program = self.program_embedding(y)\n",
    "        emb_program = self.positional_encoder(emb_program)\n",
    "        tgt_mask, pad_mask = self.get_tgt_mask(y)\n",
    "        output = self.transformer(demo_tensors, emb_program, tgt_mask=tgt_mask, tgt_key_padding_mask=pad_mask)\n",
    "        output = self.out(output)\n",
    "        output = F.softmax(output, dim=-1)\n",
    "        output = output.permute(0, 2, 1)\n",
    "        return output\n",
    "    \n",
    "    def run_action_transformer(self, actions, demo_tensors, demo_length, src_pad_mask):\n",
    "        outputs = []\n",
    "        loss = 0.0\n",
    "        for i in range(self.k):\n",
    "            y = actions[:, i, :]\n",
    "            demo = demo_tensors[i]\n",
    "            emb_actions = self.action_embedding(y)\n",
    "            emb_actions = self.positional_encoder(emb_actions)\n",
    "            tgt_mask, pad_mask = self.get_tgt_mask(y, pad_idx=PAD_IDX_ACTION)\n",
    "            output = self.action_transformer(demo, emb_actions, src_key_padding_mask=src_pad_mask[:, i, :], tgt_mask=tgt_mask, tgt_key_padding_mask=pad_mask)\n",
    "            output = self.action_out(output)\n",
    "            output = F.softmax(output, dim=-1)\n",
    "            output = output.permute(0, 2, 1)\n",
    "            loss += F.cross_entropy(output, y, ignore_index=PAD_IDX_ACTION)\n",
    "            outputs.append(output)\n",
    "        return outputs, loss / self.k \n",
    "    \n",
    "            \n",
    "    def run_perception_transformer(self, perceptions, demo_tensors, src_pad_mask):\n",
    "        outputs = []\n",
    "        loss = 0.0\n",
    "        for i in range(self.k):\n",
    "            seq = []\n",
    "            y = perceptions[:, i, :]\n",
    "            demo = demo_tensors[i]\n",
    "            emb_perceptions = self.perception_embedding(y)\n",
    "            emb_perceptions = self.positional_encoder(emb_perceptions)\n",
    "            tgt_mask, pad_mask = self.get_tgt_mask(y, pad_idx=PAD_IDX_PERCEPTION)\n",
    "            output = self.perception_transformer(demo, emb_perceptions, src_key_padding_mask=src_pad_mask[:, i, :], tgt_mask=tgt_mask, tgt_key_padding_mask=pad_mask)\n",
    "            output = self.perception_out(output)\n",
    "            output = F.softmax(output, dim=-1)\n",
    "            output = output.permute(0, 2, 1)\n",
    "            loss += F.cross_entropy(output, y, ignore_index=PAD_IDX_PERCEPTION)\n",
    "            outputs.append(output)\n",
    "        return outputs, loss / self.k\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y, actions_inp, perceptions_inp, demo_length = batch\n",
    "        batch_size = len(batch[0])\n",
    "        src_pad_mask = self.get_src_padding_mask(demo_length)\n",
    "        demo_summary_tensor, demo_list = self.stack_demos(x, batch_size, demo_length, src_pad_mask)\n",
    "        #output = self.run_program_transformer(y, demo_summary_tensor)\n",
    "        #actions, action_loss = self.run_action_transformer(actions_inp, demo_list, demo_length, src_pad_mask)\n",
    "        perceptions, perception_loss = self.run_perception_transformer(perceptions_inp, demo_list, src_pad_mask)\n",
    "        \n",
    "        # Logging to TensorBoard by default\n",
    "        #program_loss = F.cross_entropy(output, y, ignore_index=PAD_IDX)\n",
    "        #self.log(\"train_program_loss\", program_loss)\n",
    "        #self.train_program_acc(output, y)\n",
    "        #self.log('train_program_acc', self.train_program_acc, on_step=True, on_epoch=False)\n",
    "        \n",
    "        #self.log(\"train_action_loss\", action_loss)\n",
    "        #self.log(\"train_perception_loss\", perception_loss)\n",
    "        #return program_loss + action_loss + perception_loss\n",
    "        return perception_loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, actions_inp, perceptions_inp, demo_length = batch\n",
    "        #print('actions', actions_inp[1])\n",
    "        #print('perceptions', perceptions_inp[0])\n",
    "        batch_size = len(batch[0])\n",
    "        src_pad_mask = self.get_src_padding_mask(demo_length)\n",
    "        demo_summary_tensor, demo_list = self.stack_demos(x, batch_size, demo_length, src_pad_mask)\n",
    "        #output = self.run_program_transformer(y, demo_summary_tensor)\n",
    "        #actions, action_loss = self.run_action_transformer(actions_inp, demo_list, demo_length, src_pad_mask)\n",
    "        perceptions, perception_loss = self.run_perception_transformer(perceptions_inp, demo_list, src_pad_mask)\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print()\n",
    "            #print('  GT:', y[0])\n",
    "            #print('PRED:', torch.argmax(output[0], dim=1))\n",
    "            print('  GT:', perceptions_inp[0][0])\n",
    "            print('PRED:', torch.argmax(perceptions[0], dim=1)[0])\n",
    "            \n",
    "        # Logging to TensorBoard by default\n",
    "        #program_loss = F.cross_entropy(output, y, ignore_index=PAD_IDX)\n",
    "        #self.log(\"val_program_loss\", program_loss)\n",
    "        #self.val_program_acc(output, y)\n",
    "        #self.log('val_program_acc', self.val_program_acc, on_step=True, on_epoch=False)\n",
    "        \n",
    "        #self.log(\"val_action_loss\", action_loss)\n",
    "        #self.log(\"val_perception_loss\", perception_loss)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, program_len = batch\n",
    "        batch_size = len(batch[0])\n",
    "        demo_tensors = self.stack_demos(x, batch_size)\n",
    "        output = self.run_program_transformer(y, demo_tensors)\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            for i in range(batch_size):\n",
    "                print('GT:', y[i].shape)\n",
    "                print('PRED:', torch.argmax(output[i], dim=1).shape)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
    "        #optimizer = torch.optim.Adam(self.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eberhardinger/anaconda3/envs/python3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:58: LightningDeprecationWarning: Setting `Trainer(stochastic_weight_avg=True)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.stochastic_weight_avg.StochasticWeightAveraging` directly to the Trainer's `callbacks` argument instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:169: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  num_train = int(f['data_info']['num_train'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:170: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  num_test = int(f['data_info']['num_test'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:171: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  num_val = int(f['data_info']['num_val'].value)\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,699] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:29: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.dsl_type = self.data['data_info']['dsl_type'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:30: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.num_demo = int(self.data['data_info']['num_demo_per_program'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:31: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.max_demo_len = int(self.data['data_info']['max_demo_length'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:33: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.max_program_len = int(self.data['data_info']['max_program_length'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:34: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.num_program_tokens = int(self.data['data_info']['num_program_tokens'].value)\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:35: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.num_action_tokens = int(self.data['data_info']['num_action_tokens'].value)\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,709] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,710] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,714] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,715] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,719] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,734] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,736] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,737] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,739] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,740] Reading datasets/karel_dataset/data.hdf5 ...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2021-12-26 18:01:23,742] Reading Done: datasets/karel_dataset/data.hdf5\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-12-26 18:01:27.378857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "\n",
      "   | Name                    | Type               | Params\n",
      "----------------------------------------------------------------\n",
      "0  | train_program_acc       | Accuracy           | 0     \n",
      "1  | val_program_acc         | Accuracy           | 0     \n",
      "2  | cnn_encoder             | Sequential         | 807 K \n",
      "3  | program_embedding       | Embedding          | 13.1 K\n",
      "4  | action_embedding        | Embedding          | 1.8 K \n",
      "5  | perception_embedding    | Embedding          | 8.7 K \n",
      "6  | transformer_encoder     | TransformerEncoder | 1.6 M \n",
      "7  | transformer_encoder_out | Sequential         | 1.3 M \n",
      "8  | transformer             | Transformer        | 2.1 M \n",
      "9  | out                     | Linear             | 13.1 K\n",
      "10 | positional_encoder      | PositionalEncoding | 0     \n",
      "11 | action_transformer      | Transformer        | 1.8 M \n",
      "12 | action_out              | Linear             | 1.8 K \n",
      "13 | perception_transformer  | Transformer        | 1.8 M \n",
      "14 | perception_out          | Linear             | 8.7 K \n",
      "----------------------------------------------------------------\n",
      "9.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.6 M     Total params\n",
      "38.254    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eberhardinger/anaconda3/envs/python3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:47: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  program_tokens = self.data[id]['program'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:53: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  demo_data = self.data[id]['s_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:54: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_demo_data = self.data[id]['test_s_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:60: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  per_data = self.data[id]['per'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:61: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_per_data = self.data[id]['test_per'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:70: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  action_history_tokens = self.data[id]['a_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:87: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_action_history_tokens = self.data[id]['test_a_h'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:107: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  demo_length = self.data[id]['s_h_len'].value\n",
      "/home/eberhardinger/workspaces/demo2program/karel_env/dataset_karel.py:108: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test_demo_length = self.data[id]['test_s_h_len'].value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  GT: tensor([29, 29, 29, 29, 29,  9,  5,  6,  6,  6,  6, 31, 31, 31, 31, 31, 31, 31,\n",
      "        31, 31], device='cuda:0')\n",
      "PRED: tensor([18, 18, 18, 18, 18, 24, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20], device='cuda:0')\n",
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eberhardinger/anaconda3/envs/python3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|████████▎ | 391/470 [05:43<01:09,  1.14it/s, loss=2.96, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "  GT: tensor([29, 29, 29, 29, 29,  9,  5,  6,  6,  6,  6, 31, 31, 31, 31, 31, 31, 31,\n",
      "        31, 31], device='cuda:0')\n",
      "PRED: tensor([29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 31,\n",
      "        31, 31], device='cuda:0')\n",
      "\n",
      "Epoch 0:  84%|████████▎ | 393/470 [05:44<01:07,  1.14it/s, loss=2.96, v_num=0]\n",
      "Validating:   3%|▎         | 2/79 [00:02<01:13,  1.04it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 395/470 [05:46<01:05,  1.14it/s, loss=2.96, v_num=0]\n",
      "Validating:   5%|▌         | 4/79 [00:03<00:58,  1.28it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 397/470 [05:47<01:03,  1.14it/s, loss=2.96, v_num=0]\n",
      "Validating:   8%|▊         | 6/79 [00:04<00:53,  1.37it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 399/470 [05:48<01:02,  1.14it/s, loss=2.96, v_num=0]\n",
      "Validating:  10%|█         | 8/79 [00:06<00:48,  1.47it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 401/470 [05:50<01:00,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  13%|█▎        | 10/79 [00:07<00:46,  1.50it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 403/470 [05:51<00:58,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  15%|█▌        | 12/79 [00:08<00:46,  1.44it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 405/470 [05:53<00:56,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  18%|█▊        | 14/79 [00:10<00:47,  1.36it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 407/470 [05:54<00:54,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  20%|██        | 16/79 [00:11<00:48,  1.31it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 409/470 [05:56<00:53,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  23%|██▎       | 18/79 [00:13<00:44,  1.38it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 411/470 [05:57<00:51,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  25%|██▌       | 20/79 [00:14<00:42,  1.39it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 413/470 [05:58<00:49,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  28%|██▊       | 22/79 [00:16<00:40,  1.42it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 415/470 [06:00<00:47,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  30%|███       | 24/79 [00:17<00:37,  1.47it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 417/470 [06:01<00:45,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  33%|███▎      | 26/79 [00:18<00:35,  1.48it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 419/470 [06:02<00:44,  1.15it/s, loss=2.96, v_num=0]\n",
      "Validating:  35%|███▌      | 28/79 [00:20<00:35,  1.43it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 421/470 [06:04<00:42,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  38%|███▊      | 30/79 [00:21<00:35,  1.37it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 423/470 [06:05<00:40,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  41%|████      | 32/79 [00:23<00:34,  1.35it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 425/470 [06:07<00:38,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  43%|████▎     | 34/79 [00:24<00:33,  1.33it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 427/470 [06:08<00:37,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  46%|████▌     | 36/79 [00:26<00:31,  1.38it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 429/470 [06:10<00:35,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  48%|████▊     | 38/79 [00:27<00:28,  1.43it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 431/470 [06:11<00:33,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  51%|█████     | 40/79 [00:28<00:27,  1.42it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 433/470 [06:13<00:31,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  53%|█████▎    | 42/79 [00:30<00:25,  1.47it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 435/470 [06:14<00:30,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  56%|█████▌    | 44/79 [00:31<00:24,  1.41it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 437/470 [06:15<00:28,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  58%|█████▊    | 46/79 [00:33<00:23,  1.39it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 439/470 [06:17<00:26,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  61%|██████    | 48/79 [00:34<00:22,  1.40it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 441/470 [06:18<00:24,  1.16it/s, loss=2.96, v_num=0]\n",
      "Validating:  63%|██████▎   | 50/79 [00:36<00:20,  1.38it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 443/470 [06:20<00:23,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  66%|██████▌   | 52/79 [00:37<00:19,  1.37it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 445/470 [06:21<00:21,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  68%|██████▊   | 54/79 [00:39<00:18,  1.37it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 447/470 [06:23<00:19,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  71%|███████   | 56/79 [00:40<00:16,  1.43it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 449/470 [06:24<00:17,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  73%|███████▎  | 58/79 [00:41<00:14,  1.46it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 451/470 [06:25<00:16,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  76%|███████▌  | 60/79 [00:43<00:13,  1.37it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 453/470 [06:27<00:14,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  78%|███████▊  | 62/79 [00:44<00:12,  1.40it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 455/470 [06:28<00:12,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  81%|████████  | 64/79 [00:46<00:10,  1.45it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 457/470 [06:30<00:11,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  84%|████████▎ | 66/79 [00:47<00:09,  1.39it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 459/470 [06:31<00:09,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  86%|████████▌ | 68/79 [00:49<00:08,  1.31it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 461/470 [06:33<00:07,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  89%|████████▊ | 70/79 [00:50<00:06,  1.30it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 463/470 [06:34<00:05,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  91%|█████████ | 72/79 [00:52<00:05,  1.36it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 465/470 [06:36<00:04,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  94%|█████████▎| 74/79 [00:53<00:03,  1.42it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 467/470 [06:37<00:02,  1.17it/s, loss=2.96, v_num=0]\n",
      "Validating:  96%|█████████▌| 76/79 [00:54<00:02,  1.48it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 469/470 [06:38<00:00,  1.18it/s, loss=2.96, v_num=0]\n",
      "Validating:  99%|█████████▊| 78/79 [00:55<00:00,  1.90it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 470/470 [06:39<00:00,  1.18it/s, loss=2.96, v_num=0]\n",
      "Epoch 1:  70%|███████   | 329/470 [04:45<02:02,  1.15it/s, loss=2.72, v_num=0]"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = ProgramSynthesisTransformer()\n",
    "train_loader = KarelVideoDataModule(batch_size=64)\n",
    "# most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
    "# trainer = pl.Trainer(gpus=8) (if you have GPUs)\n",
    "trainer = pl.Trainer(gpus=1, gradient_clip_val=0.5, stochastic_weight_avg=True)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1, resume_from_checkpoint='lightning_logs/version_5/checkpoints/epoch=5-step=2345.ckpt')\n",
    "trainer.test(model=model, datamodule=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karel_env.dsl import get_KarelDSL\n",
    "vocab = get_KarelDSL(dsl_type=dataset_train.dsl_type.decode(), seed=123)\n",
    "vocab.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-program",
   "language": "python",
   "name": "transformer-program"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
